inherit:
  - ../user_datasets/__DATASET_ID__.yaml
  - ../models/mistral-small.yaml
  - ../trainers/gpt2-small.yaml

run_id: __DATASET_ID__

artifacts:
  cache_dir: CACHE_PATH/__DATASET_ID__
  run_dir: CHECKPOINT_PATH/__DATASET_ID__

effective_bsz: 8

resume: true
resume_checkpoint: null

checkpoint_frequency:
  - [100, 1000]
  - [500, 5000]
  - [1000, 10000]

seed: 42

training_arguments:
  max_steps: 10000
  per_device_train_batch_size: 2
  gradient_accumulation_steps: 4
  logging_steps: 10
  eval_steps: 200
  save_steps: 200
  weight_decay: 0.01
  warmup_steps: 1000
  lr_scheduler_type: linear
  prediction_loss_only: true
  dataloader_num_workers: 2
  fp16: true
