run_id: none_A+P
model_name: gpt2
effective_bsz: 96
seed: 42
block_size: 1024
resume: true
resume_checkpoint: null
checkpoint_frequency:
- - 100
  - 1000
- - 500
  - 5000
- - 1000
  - 10000
artifacts:
  cache_dir: /home/hd49/relational-casemarking-learning/cache/none_A+P
  run_dir: /home/hd49/relational-casemarking-learning/checkpoints/none_A+P
training_arguments:
  max_steps: 8000
  per_device_train_batch_size: 8
  optim: adamw_torch_fused
  bf16: true
  fp16: false
  gradient_checkpointing: false
  learning_rate: 2.0e-05
  weight_decay: 0.01
  warmup_steps: 0
  warmup_ratio: 0.03
  lr_scheduler_type: cosine
  logging_steps: 50
  eval_steps: 1000
  save_steps: 1000
  save_total_limit: 3
  evaluation_strategy: steps
  save_strategy: steps
  load_best_model_at_end: true
  metric_for_best_model: eval_loss
  greater_is_better: false
  prediction_loss_only: true
  dataloader_num_workers: 6
  dataloader_pin_memory: true
  report_to:
  - tensorboard
data:
  train_files:
  - /home/hd49/relational-casemarking-learning/data/perturbed_model/none_A+P/wiki_all_train_unaffected.txt
  eval_files:
  - /home/hd49/relational-casemarking-learning/data/perturbed_model/none_A+P/wiki_all_valid_unaffected.txt
