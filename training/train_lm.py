#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Train a causal LM from a YAML (generated by tools/generate_yaml.py).

Usage:
    python -m training.train_lm --mode rule --strategy A+P
    python -m training.train_lm --mode rule --strategy A+P --with-invalid
"""

import os

# ---- 防碎片化设置（尽早设置，防显存碎片 OOM）----
if "PYTORCH_CUDA_ALLOC_CONF" not in os.environ:
    os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "max_split_size_mb:128"
    print(f"[Info] Set PYTORCH_CUDA_ALLOC_CONF={os.environ['PYTORCH_CUDA_ALLOC_CONF']}")

import csv
import json
import math
import time
import argparse
from pathlib import Path
from typing import List, Dict, Any, Optional

import yaml
import torch
from datasets import load_dataset, concatenate_datasets
from transformers import (
    AutoTokenizer,
    AutoModelForCausalLM,
    DataCollatorForLanguageModeling,
    Trainer,
    TrainingArguments,
    TrainerCallback,
)

from utils import CHECKPOINT_PATH, CONFIG_PATH, CACHE_PATH

# ---- perf knobs ----
torch.set_num_threads(1)
torch.set_num_interop_threads(1)
if torch.backends.cudnn.is_available():
    torch.backends.cudnn.benchmark = True
# TF32: L4 友好，数值等效 FP32，吞吐高
try:
    torch.backends.cuda.matmul.allow_tf32 = True
    torch.backends.cudnn.allow_tf32 = True
    torch.set_float32_matmul_precision("high")
except Exception:
    pass


# -------------------------
# Helpers
# -------------------------
def _expand(p: str) -> str:
    return os.path.expandvars(os.path.expanduser(p))


def _build_dataset(files: List[str]):
    """支持 .txt（每行一条）和 .jsonl/.json（每行 {"text": "..."}）"""
    if not files:
        return None
    ds_list = []
    for f in files:
        f = _expand(f)
        if f.endswith(".txt"):
            ds = load_dataset("text", data_files=f, split="train")
        elif f.endswith(".jsonl") or f.endswith(".json"):
            ds = load_dataset("json", data_files=f, split="train")
            if "text" not in ds.column_names:
                raise ValueError(f"{f} 需要包含字段 'text'")
        else:
            raise ValueError(f"不支持的文件类型：{f}")
        ds_list.append(ds)
    return concatenate_datasets(ds_list) if len(ds_list) > 1 else ds_list[0]


def _group_texts(examples: Dict[str, list], block_size: int):
    """拼接后切成固定长度块；仅处理 list[list[int]] 键，避免误入非张量列"""
    keys = [k for k, v in examples.items() if isinstance(v, list) and v and isinstance(v[0], list)]
    concatenated = {k: sum(examples[k], []) for k in keys}
    total_len = len(concatenated.get("input_ids", []))
    total_len = (total_len // block_size) * block_size
    result = {k: [t[i:i + block_size] for i in range(0, total_len, block_size)] for k, t in concatenated.items()}
    if "input_ids" not in result:
        result["input_ids"] = []
    result["labels"] = result["input_ids"].copy()
    return result


def _find_last_checkpoint(run_dir: Path) -> Optional[Path]:
    if not run_dir.exists():
        return None
    cks = [p for p in run_dir.glob("checkpoint-*") if p.is_dir()]
    if not cks:
        return None
    cks.sort(key=lambda p: int(p.name.split("-")[-1]))
    return cks[-1]


def _count_total_tokens(tokenized_ds) -> int:
    """统计 tokenizer 之后的总 token 数（未按 block_size 截断）"""
    return int(sum(len(x) for x in tokenized_ds["input_ids"]))


# -------------------------
# Callbacks
# -------------------------
class ValidPPLLogger(TrainerCallback):
    """将 eval_loss -> ppl 写入 CSV，并打印一行摘要；若启用 tensorboard 也写入"""
    def __init__(self, csv_path: Path):
        self.csv_path = csv_path
        self._csv_path_str = str(csv_path)
        csv_path.parent.mkdir(parents=True, exist_ok=True)
        if not csv_path.exists():
            with open(self._csv_path_str, "w", newline="") as f:
                csv.writer(f).writerow(["step", "eval_loss", "ppl", "wall_time"])
        self.tb_writer = None

    def on_evaluate(self, args, state, control, metrics, **kwargs):
        if "eval_loss" not in metrics:
            return
        eval_loss = float(metrics["eval_loss"])
        ppl = float(math.exp(eval_loss))
        step = int(state.global_step)
        with open(self._csv_path_str, "a", newline="") as f:
            csv.writer(f).writerow([step, eval_loss, ppl, time.time()])
        if state.is_world_process_zero:
            print(f"[Eval] step={step} eval_loss={eval_loss:.6f} ppl={ppl:.3f}")
            try:
                if self.tb_writer is not None:
                    self.tb_writer.add_scalar("eval_ppl", ppl, step)
            except Exception:
                pass


class ThroughputLogger(TrainerCallback):
    """根据 effective_bsz 与 block_size 粗略估算 tokens/s，仅打印"""
    def __init__(self, tokens_per_step: int):
        self.tokens_per_step = tokens_per_step
        self.t0 = None

    def on_step_begin(self, args, state, control, **kwargs):
        self.t0 = time.time()

    def on_step_end(self, args, state, control, **kwargs):
        if self.t0 is None:
            return
        dt = time.time() - self.t0
        tps = self.tokens_per_step / max(dt, 1e-6)
        if state.is_world_process_zero and (state.global_step % max(1, args.logging_steps) == 0):
            print(f"[Speed] step={state.global_step} ~{tps:,.0f} tokens/s")


# -------------------------
# Main
# -------------------------
def main():
    ap = argparse.ArgumentParser()
    ap.add_argument("--mode", type=str, required=True)
    ap.add_argument("--strategy", type=str, required=True)
    ap.add_argument("--with-invalid", action="store_true")
    args = ap.parse_args()

    dataset_id = f"{args.mode}_{args.strategy}"
    run_id = f"{dataset_id}_with_invalid" if args.with_invalid else dataset_id

    cfg_path = Path(CONFIG_PATH) / f"{run_id}.yaml"
    if not cfg_path.exists():
        raise FileNotFoundError(f"Config not found: {cfg_path}")

    with open(cfg_path, "r", encoding="utf-8") as f:
        cfg: Dict[str, Any] = yaml.safe_load(f)

    data_cfg: Dict[str, Any] = cfg.get("data", {})
    train_files: List[str] = data_cfg.get("train_files", [])
    eval_files: List[str] = data_cfg.get("eval_files", [])

    # 输出目录
    run_dir = Path(cfg.get("artifacts", {}).get("run_dir", str(Path(CHECKPOINT_PATH) / run_id)))
    run_dir = Path(_expand(str(run_dir)))
    run_dir.mkdir(parents=True, exist_ok=True)

    # Cache（固定用 utils.CACHE_PATH/run_id）
    cache_dir = Path(CACHE_PATH) / run_id
    cache_dir.mkdir(parents=True, exist_ok=True)
    os.environ["HF_HOME"] = str(cache_dir)
    os.environ["HF_DATASETS_CACHE"] = str(cache_dir / "datasets")

    # 训练参数
    targs = dict(cfg.get("training_arguments", {}))
    model_name = cfg.get("model_name", "gpt2")
    block_size = int(cfg.get("block_size", 1024))
    seed = int(cfg.get("seed", 42))
    effective_bsz = cfg.get("effective_bsz", None)

    # 先把基础参数打印出来（最开头）
    print("[Info] ===== Training Config (early print) =====")
    print(f"[Info] run_id={run_id}")
    print(f"[Info] model={model_name}")
    print(f"[Info] block_size={block_size}, seed={seed}")
    print(f"[Info] train_files={len(train_files)} | eval_files={len(eval_files)}")
    print(f"[Info] output_dir={run_dir}")
    print(f"[Info] cache_dir={cache_dir}")
    print("[Info] =========================================")

    if effective_bsz is not None:
        pbsz = int(targs.get("per_device_train_batch_size", 1))
        gas = math.ceil(float(effective_bsz) / max(pbsz, 1))
        targs["gradient_accumulation_steps"] = int(gas)

    # 有 eval_files 时强制按 steps 评测（便于记录曲线）
    if eval_files:
        targs["evaluation_strategy"] = "steps"
        targs.setdefault("save_strategy", "steps")

    # 数据
    train_ds = _build_dataset(train_files)
    if train_ds is None:
        raise RuntimeError("train_files 为空")
    eval_ds = _build_dataset(eval_files) if eval_files else None

    # tokenizer / model
    tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True, cache_dir=str(cache_dir))
    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token
    model = AutoModelForCausalLM.from_pretrained(model_name, cache_dir=str(cache_dir))

    # 若配置要求开启 gradient checkpointing，显式处理兼容项
    if bool(targs.get("gradient_checkpointing", False)):
        try:
            model.gradient_checkpointing_enable(gradient_checkpointing_kwargs={"use_reentrant": False})
        except TypeError:
            model.gradient_checkpointing_enable()
        model.config.use_cache = False  # 与 checkpointing 不兼容

    # tokenize
    def tok_fn(batch):
        return tokenizer(batch["text"], return_attention_mask=False)

    train_tok = train_ds.map(tok_fn, batched=True, remove_columns=train_ds.column_names)
    eval_tok = eval_ds.map(tok_fn, batched=True, remove_columns=eval_ds.column_names) if eval_ds else None

    # ---- 统计训练集 token 情况（group 之前）----
    raw_train_tokens = _count_total_tokens(train_tok)              # 未按 block_size 截断
    usable_train_tokens = (raw_train_tokens // block_size) * block_size

    # group
    train_tok = train_tok.map(lambda ex: _group_texts(ex, block_size), batched=True, batch_size=1000)
    if eval_tok:
        eval_tok = eval_tok.map(lambda ex: _group_texts(ex, block_size), batched=True, batch_size=1000)

    collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)

    # Trainer
    training_args = TrainingArguments(output_dir=str(run_dir), seed=seed, **targs)

    # ---- 计算/打印关键信息（步数/吞吐相关）----
    pbsz = training_args.per_device_train_batch_size
    gas = training_args.gradient_accumulation_steps
    eff_bsz_runtime = pbsz * gas
    tokens_per_step = eff_bsz_runtime * block_size
    max_steps = training_args.max_steps if training_args.max_steps and training_args.max_steps > 0 else None
    approx_steps_per_epoch = (usable_train_tokens // tokens_per_step) if tokens_per_step > 0 else None

    # 保存到 JSON，方便后续追踪
    stats_json = {
        "model_name": model_name,
        "block_size": block_size,
        "per_device_train_batch_size": pbsz,
        "gradient_accumulation_steps": gas,
        "effective_bsz_runtime": eff_bsz_runtime,
        "raw_train_tokens": raw_train_tokens,
        "usable_train_tokens": usable_train_tokens,
        "tokens_per_step": tokens_per_step,
        "approx_steps_per_epoch": approx_steps_per_epoch,
        "max_steps": max_steps,
    }
    with open(run_dir / "train_token_stats.json", "w", encoding="utf-8") as f:
        json.dump(stats_json, f, ensure_ascii=False, indent=2)

    # 友好打印
    print("[Info] ===== Token Accounting =====")
    print(f"[Info] raw_train_tokens={raw_train_tokens:,}")
    print(f"[Info] usable_train_tokens (÷{block_size})={usable_train_tokens:,}")
    print(f"[Info] per_step_tokens = effective_bsz({eff_bsz_runtime}) × block_size({block_size}) = {tokens_per_step:,}")
    if approx_steps_per_epoch is not None:
        print(f"[Info] approx_steps_per_epoch ≈ {approx_steps_per_epoch:,}")
    if max_steps is not None:
        print(f"[Info] planned_max_steps = {max_steps:,}  (~{(max_steps * tokens_per_step):,} tokens total)")
    print("[Info] =========================================")

    trainer = Trainer(
        model=model,
        args=training_args,
        train_dataset=train_tok,
        eval_dataset=eval_tok,
        data_collator=collator,
        tokenizer=tokenizer,
    )

    # 回调：记录 valid ppl + 打印吞吐
    if eval_tok is not None:
        csv_path = run_dir / "valid_metrics.csv"
        ppl_cb = ValidPPLLogger(csv_path)
        trainer.add_callback(ppl_cb)
        # tensorboard（如启用）
        if "tensorboard" in (targs.get("report_to") or []):
            try:
                from torch.utils.tensorboard import SummaryWriter
                ppl_cb.tb_writer = SummaryWriter(log_dir=str(run_dir))
            except Exception:
                ppl_cb.tb_writer = None

    if tokens_per_step > 0:
        trainer.add_callback(ThroughputLogger(tokens_per_step))

    # resume
    resume_flag = bool(cfg.get("resume", False))
    resume_ckpt_cfg = cfg.get("resume_checkpoint", None)
    resume_from: Optional[str] = None
    if resume_flag:
        if resume_ckpt_cfg:
            resume_from = _expand(resume_ckpt_cfg)
        else:
            last = _find_last_checkpoint(run_dir)
            if last:
                resume_from = str(last)

    # 再次打印一遍简要配置信息（含 GAS 推导后的值）
    print(f"[Info] per_device_train_batch_size={pbsz} "
          f"gas={gas} "
          f"effective_bsz~={eff_bsz_runtime}")

    # train
    trainer.train(resume_from_checkpoint=resume_from)
    trainer.save_model()
    tokenizer.save_pretrained(run_dir)

    print(f"[OK] Training finished. Checkpoints at: {run_dir}")
    print(f"[OK] Cache stored at: {cache_dir}")
    if eval_tok is not None:
        print(f"[OK] Valid PPL CSV: {run_dir / 'valid_metrics.csv'}")


if __name__ == "__main__":
    main()
