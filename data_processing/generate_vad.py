import os
import json
import random

# === å‚æ•°è®¾ç½® ===
input_txt = "/home/dengh/workspace/relational-casemarking-learning/data/perturbed/rule/combined.txt"         # æ¯è¡Œä¸€å¥
output_dir = "/home/dengh/workspace/relational-casemarking-learning/data/perturbed/rule/train"
name = "rule"
validation_ratio = 0.05

# === è¯»å–æ‰€æœ‰éç©ºè¡Œ ===
with open(input_txt, "r", encoding="utf-8") as f:
    lines = [line.strip() for line in f if line.strip()]

print(f"ğŸ“˜ æ€»è¡Œæ•°ï¼ˆæ ·æœ¬ï¼‰ï¼š{len(lines)}")

# === æ‰“ä¹±å¹¶æ‹†åˆ† ===
random.seed(42)
random.shuffle(lines)

split_idx = int(len(lines) * (1 - validation_ratio))
train_data = lines[:split_idx]
val_data = lines[split_idx:]

# === è½¬æˆ {"text": "..."} æ ¼å¼
train_data = [{"text": line} for line in train_data]
val_data = [{"text": line} for line in val_data]

# === è¾“å‡ºè·¯å¾„ ===
os.makedirs(output_dir, exist_ok=True)
train_path = os.path.join(output_dir, f"{name}.train.jsonl")
val_path = os.path.join(output_dir, f"{name}.validation.jsonl")

# === å†™å…¥ JSONL æ–‡ä»¶ ===
with open(train_path, "w", encoding="utf-8") as f:
    for item in train_data:
        f.write(json.dumps(item, ensure_ascii=False) + "\n")

with open(val_path, "w", encoding="utf-8") as f:
    for item in val_data:
        f.write(json.dumps(item, ensure_ascii=False) + "\n")

print(f"âœ… æ‹†åˆ†å®Œæˆï¼šè®­ç»ƒé›† {len(train_data)} è¡Œï¼ŒéªŒè¯é›† {len(val_data)} è¡Œ")
print(f"âœ” Train æ–‡ä»¶ï¼š{train_path}")
print(f"âœ” Val æ–‡ä»¶ï¼š  {val_path}")
