import spacy
import argparse

nlp = spacy.load("en_core_web_sm")

def extract_structure(sentence):
    doc = nlp(sentence)
    result = {
        "subject": None,
        "verb": None,
        "objects": [],
        "complements": []
    }

    for token in doc:
        if token.dep_ == "ROOT" and token.pos_ in {"VERB", "AUX"}:
            verb_phrase = [w.text for w in sorted(
                [token] + [aux for aux in token.children if aux.dep_ in {"aux", "auxpass"}],
                key=lambda x: x.i
            )]
            result["verb"] = " ".join(verb_phrase)

            # ä¸»è¯­
            for child in token.children:
                if child.dep_ in {"nsubj", "nsubj:pass"}:
                    result["subject"] = " ".join(w.text for w in child.subtree)

            # ç›´æ¥å®¾è¯­ / ä»å¥å®¾è¯­
            for child in token.children:
                if child.dep_ in {"obj", "dobj", "attr", "ccomp"}:
                    phrase = " ".join(w.text for w in child.subtree)
                    result["objects"].append(("direct/clausal", phrase))

                # ä»‹è¯å®¾è¯­
                elif child.dep_ == "prep":
                    for pobj in child.children:
                        if pobj.dep_ == "pobj":
                            phrase = f"{child.text} " + " ".join(w.text for w in pobj.subtree)
                            result["objects"].append(("prepositional", phrase))

                # è¡¥è¯­ï¼ˆä¸å®šå¼ã€åŠ¨åè¯ï¼‰
                elif child.dep_ == "xcomp":
                    phrase = " ".join(w.text for w in child.subtree)
                    result["complements"].append(phrase)

    return result

def process_file(file_path, max_lines=10):
    with open(file_path, "r", encoding="utf-8") as f:
        lines = [line.strip() for line in f if line.strip()]

    for i, line in enumerate(lines[:max_lines]):
        print(f"\nğŸ” ç¬¬ {i+1} å¥ï¼š{line}")
        result = extract_structure(line)

        print("ğŸŸ¦ Subject:", result["subject"] if result["subject"] else "(æ— )")
        print("ğŸŸ¨ Verb:", result["verb"] if result["verb"] else "(æ— )")

        if result["objects"]:
            print("ğŸŸ¥ Objects:")
            for kind, phrase in result["objects"]:
                print(f"    - [{kind}] {phrase}")
        else:
            print("ğŸŸ¥ Objects: (æ— )")

        if result["complements"]:
            print("ğŸŸ© Complements:")
            for comp in result["complements"]:
                print(f"    - {comp}")
        else:
            print("ğŸŸ© Complements: (æ— )")

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="ç»“æ„æå–å™¨ï¼šä¸»è¯­ / è°“è¯­ / å®¾è¯­ / è¡¥è¯­")
    parser.add_argument("--input", type=str, required=True, help="è¾“å…¥å¥å­æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--max_lines", type=int, default=10, help="æœ€å¤§å¤„ç†å¥æ•°")
    args = parser.parse_args()

    process_file(args.input, args.max_lines)