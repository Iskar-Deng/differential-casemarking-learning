"""
parse_with_stanza.py

è¯»å–ä¸€ä¸ªå¥å­æ–‡ä»¶ï¼Œä½¿ç”¨ Stanza åˆ†æå¥æ³•ç»“æ„å¹¶æ‰“å°ç»“æœã€‚

ä½¿ç”¨ç¤ºä¾‹ï¼š
    python parse_with_stanza.py --input data/filtered/cbt_clean.txt --max_lines 10
"""

import stanza
import argparse

def analyze_sentences(file_path, max_lines=10):
    nlp = stanza.Pipeline("en", processors="tokenize,pos,lemma,depparse", use_gpu=False)

    with open(file_path, "r", encoding="utf-8") as f:
        sentences = [line.strip() for line in f if line.strip()]

    for i, sent in enumerate(sentences[:max_lines]):
        print(f"\nğŸ” ç¬¬ {i+1} å¥ï¼š{sent}")
        doc = nlp(sent)
        for sentence in doc.sentences:
            print(f"{'Index':<5} {'Word':<15} {'Lemma':<15} {'POS':<6} {'Head':<5} {'Dep'}")
            for word in sentence.words:
                print(f"{word.id:<5} {word.text:<15} {word.lemma:<15} {word.upos:<6} {word.head:<5} {word.deprel}")
        print("-" * 60)

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="ä½¿ç”¨ Stanza å¯¹æ–‡æœ¬æ–‡ä»¶è¿›è¡Œå¥æ³•åˆ†æ")
    parser.add_argument("--input", type=str, required=True, help="è¾“å…¥çš„å¥å­æ–‡æœ¬æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--max_lines", type=int, default=10, help="è¦åˆ†æçš„æœ€å¤§å¥å­æ•°")
    args = parser.parse_args()

    analyze_sentences(args.input, args.max_lines)
